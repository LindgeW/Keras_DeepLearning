{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: output/gan-cifar10\\history.csv\n",
      "generator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         4803      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,868,915\n",
      "Trainable params: 1,860,667\n",
      "Non-trainable params: 8,248\n",
      "_________________________________________________________________\n",
      "discriminator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 1)           6401      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,035,649\n",
      "Trainable params: 1,035,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "====== 1\n",
      "====== 2\n",
      "====== 3\n",
      "====== 4\n",
      "====== 5\n",
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(4, 50000, 1) (4, 10000, 1)\n",
      "====== 6\n",
      "====== 7\n",
      "(50000, 32, 3, 32) (4, 50000, 1)\n",
      "(10000, 32, 3, 32) (4, 10000, 1)\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " 2752/50000 [>.............................] - ETA: 1:30:43 - loss: 11.1540 - generator_loss: 10.0932 - generator_yfake_loss: 2.2109 - generator_yreal_loss: 7.8462 - discriminator_loss: 1.0608 - discriminator_yfake_loss: 0.6669 - discriminator_yreal_loss: 0.3579"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation\n",
    "from keras.layers.convolutional import UpSampling2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from keras_adversarial.legacy import Dense, BatchNormalization, fit, l1l2, Convolution2D, AveragePooling2D\n",
    "import keras.backend as K\n",
    "from cifar10_utils import cifar10_data\n",
    "from image_utils import dim_ordering_fix, dim_ordering_unfix, dim_ordering_shape\n",
    "\n",
    "\n",
    "def model_generator():\n",
    "    model = Sequential()\n",
    "    nch = 256\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "    h = 5\n",
    "    model.add(Dense(nch * 4 * 4, input_dim=100, W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0))\n",
    "    model.add(Reshape(dim_ordering_shape((nch, 4, 4))))\n",
    "    model.add(Convolution2D(nch // 2, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(nch // 2, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(nch // 4, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(3, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_discriminator():\n",
    "    nch = 256\n",
    "    h = 5\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "\n",
    "    c1 = Convolution2D(nch // 4, h, h, border_mode='same', W_regularizer=reg(), input_shape=dim_ordering_shape((3, 32, 32)))\n",
    "    c2 = Convolution2D(nch // 2, h, h, border_mode='same', W_regularizer=reg())\n",
    "    c3 = Convolution2D(nch, h, h, border_mode='same', W_regularizer=reg())\n",
    "    c4 = Convolution2D(1, h, h, border_mode='same', W_regularizer=reg())\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(c1)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c3)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c4)\n",
    "    model.add(AveragePooling2D(pool_size=(4, 4), border_mode='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator, discriminator, latent_dim,\n",
    "                targets=gan_targets, loss='binary_crossentropy'):\n",
    "    csvpath = os.path.join(path, \"history.csv\")\n",
    "    if os.path.exists(csvpath):\n",
    "        print(\"Already exists: {}\".format(csvpath))\n",
    "        return\n",
    "\n",
    "    print(\"Training: {}\".format(csvpath))\n",
    "    # gan (x - > yfake, yreal), z is gaussian generated on GPU\n",
    "    # can also experiment with uniform_latent_sampling\n",
    "    print(\"generator:\")\n",
    "    generator.summary()\n",
    "    print(\"discriminator:\")\n",
    "    discriminator.summary()\n",
    "\n",
    "    gan = simple_gan(generator=generator,\n",
    "                     discriminator=discriminator,\n",
    "                     latent_sampling=normal_latent_sampling((latent_dim,)))\n",
    "\n",
    "    # build adversarial model\n",
    "    model = AdversarialModel(base_model=gan,\n",
    "                             player_params=[generator.trainable_weights, discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers=[opt_g, opt_d],\n",
    "                              loss=loss)\n",
    "\n",
    "    # create callback to generate images\n",
    "    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "\n",
    "    def generator_sampler():\n",
    "        xpred = dim_ordering_unfix(generator.predict(zsamples)).transpose((0, 2, 3, 1))\n",
    "        print(\"xpred:\",xpred.shape)\n",
    "        return xpred.reshape((10, 10) + xpred.shape[1:])\n",
    "\n",
    "    generator_cb = ImageGridCallback(os.path.join(path, \"epoch-{:03d}.png\"), generator_sampler, cmap=None)\n",
    "\n",
    "    # train model\n",
    "    xtrain, xtest = cifar10_data()\n",
    "    y = targets(xtrain.shape[0])\n",
    "    ytest = targets(xtest.shape[0])\n",
    "    print(xtrain.shape,xtest.shape) #(50000, 32, 32, 3) (10000, 32, 32, 3)    \n",
    "    print(np.shape(y),np.shape(ytest)) #(4, 50000, 1) (4, 10000, 1)\n",
    "    \n",
    "    callbacks = [generator_cb]\n",
    "    \n",
    "    if K.backend() == \"tensorflow\":\n",
    "        callbacks.append(TensorBoard(log_dir=os.path.join(path, 'logs'), histogram_freq=0, write_graph=True, write_images=True))\n",
    "        \n",
    "    print(np.shape(dim_ordering_fix(xtrain)),np.shape(y)) #(50000, 32, 3, 32) (4, 50000, 1)\n",
    "    print(np.shape(dim_ordering_fix(xtest)),np.shape(ytest)) #(10000, 32, 3, 32) (4, 10000, 1)\n",
    "    \n",
    "#     history = fit(model, x=dim_ordering_fix(xtrain), y=y, validation_data=(dim_ordering_fix(xtest), ytest),\n",
    "#                   callbacks=callbacks, nb_epoch=nb_epoch, batch_size=32)\n",
    "    history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest),\n",
    "                  callbacks=callbacks, nb_epoch=nb_epoch, batch_size=32)\n",
    "    \n",
    "    # save history to CSV\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(csvpath)\n",
    "\n",
    "    # save models\n",
    "    generator.save(os.path.join(path, \"generator.h5\"))\n",
    "    discriminator.save(os.path.join(path, \"discriminator.h5\"))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # z \\in R^100\n",
    "    latent_dim = 100\n",
    "    # x \\in R^{28x28}\n",
    "    # generator (z -> x)\n",
    "    generator = model_generator()\n",
    "    # discriminator (x -> y)\n",
    "    discriminator = model_discriminator()\n",
    "    example_gan(AdversarialOptimizerSimultaneous(), \"output/gan-cifar10\",\n",
    "                opt_g=Adam(lr=1e-4, decay=1e-5),\n",
    "                opt_d=Adam(lr=1e-3, decay=1e-5),\n",
    "                nb_epoch=100, generator=generator, discriminator=discriminator,\n",
    "                latent_dim=latent_dim)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 3)\n",
      "(3, 1, 4)\n",
      "(1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[[1,2,3],[3,4,5],[5,6,7],[7,8,9]]])\n",
    "print(x.shape)\n",
    "print(x.transpose(2,0,1).shape)\n",
    "print(x.transpose(2,0,1).transpose(1,2,0).shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
