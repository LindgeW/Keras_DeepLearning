{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环神经网络（RNN）：主要用于挖掘数据中的时序信息以及语义信息的深度表达能力,在语音识别,语言模型,机器翻译以及时序分析方面也被广泛应用.\n",
    "\n",
    "举个例子,比如文本序列的预测,预测句子的下一个单词是什么,一般需要当前的单词以及前面的单词,因为句子的各之间不独立的,比如当前单词是is,前一个词汇是sky,那么下一个词汇很大的概率是blue,RNN就是通过对大量的序列数据的学习,网络会记忆之前的信息,并依据之前的信息来推测后来的输出信息.\n",
    "\n",
    "所以在RNN中隐藏层节点之间是有连接的,隐藏层当前的状态是由但前和输入和上一个时间点的隐藏层(状态)输出共同决定的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# np.random.seed(1337) # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# X shape (60,000 28x28), y shape (10,000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 28, 28) / 255. # normalize\n",
    "X_test = X_test.reshape(-1, 28, 28) / 255. # normalize\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型\n",
    "Recurrent层是抽象类，不要在模型中直接应用，应使用它的子类LSTM，GRU或SimpleRNN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "为了使用RNN，我们将图像理解为序列化数据。\n",
    "每一行作为一个输入单元，所以输入数据大小INPUT_SIZE = 28； \n",
    "先是第1行输入，再是第2行，第3行，第4行，…，第28行输入， \n",
    "这就是一张图片也就是一个序列，所以步长TIME_STEPS = 28。\n",
    "'''\n",
    "TIME_STEPS = 28 #要读取多少个时间点的数据，如果一次读一行需要读28次，相当于图片的高度\n",
    "INPUT_SIZE = 28 # same as the width of the image\n",
    "BATCH_SIZE = 50 #批的大小\n",
    "BATCH_INDEX = 0 #批的起始索引\n",
    "OUTPUT_SIZE = 10 #分类结果的数量\n",
    "CELL_SIZE = 50 #隐层中的输出维度\n",
    "\n",
    "# build RNN model\n",
    "model = Sequential()\n",
    "# RNN cell\n",
    "model.add(SimpleRNN( #全连接RNN网络，RNN的输出会被回馈到输入\n",
    "    input_shape=(TIME_STEPS, INPUT_SIZE), # Or:input_dim=INPUT_SIZE, input_length=TIME_STEPS,\n",
    "    units=CELL_SIZE, #输出维度\n",
    "    unroll=True,\n",
    "#     unroll 默认为False，若为True，则循环层将被展开，否则就使用符号化的循环。\n",
    "#     当使用TensorFlow为后端时，循环网络本来就是展开的，因此该层不做任何事情。\n",
    "#     层展开会占用更多的内存，但会加速RNN的运算。层展开只适用于短序列。\n",
    "))\n",
    "# output layer\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 50)                3950      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 5,790\n",
      "Trainable params: 5,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "# optimizer\n",
    "adam = Adam(LR)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cost:  0.228961184621 test accuracy:  0.937900006771\n",
      "test cost:  0.173115715384 test accuracy:  0.95300000906\n",
      "test cost:  0.187467262149 test accuracy:  0.947600007057\n",
      "test cost:  0.197130635381 test accuracy:  0.948099970818\n",
      "test cost:  0.186225309968 test accuracy:  0.95039999485\n",
      "test cost:  0.177072882652 test accuracy:  0.952499985695\n",
      "test cost:  0.189168646932 test accuracy:  0.949100017548\n",
      "test cost:  0.175225347281 test accuracy:  0.95450001955\n",
      "test cost:  0.190782010555 test accuracy:  0.948300004005\n",
      "Over!\n"
     ]
    }
   ],
   "source": [
    "# batch training\n",
    "for step in range(4001):\n",
    "    # data shape = (batch_num, steps, inputs/outputs)\n",
    "    X_batch = X_train[BATCH_INDEX:BATCH_INDEX+BATCH_SIZE,:,:]\n",
    "    Y_batch = y_train[BATCH_INDEX:BATCH_INDEX+BATCH_SIZE,:]\n",
    "    cost = model.train_on_batch(X_batch, Y_batch)\n",
    "    BATCH_INDEX += BATCH_SIZE\n",
    "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "    if step % 500 == 0: #每 500 步输出一下测试集的准确率和损失\n",
    "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "# model.fit(X_train, y_train, epochs=2, batch_size=BATCH_SIZE)    \n",
    "# cost, accuracy = model.evaluate(X_test, y_test)\n",
    "# print('test cost: ', cost, ' test accuracy: ', accuracy)\n",
    "\n",
    "print('Over!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cifar10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,122,186\n",
      "Trainable params: 2,122,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "(x_train,y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_test = np_utils.to_categorical(y_test, 10).reshape(y_test.shape[0],-1)\n",
    "a, b = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12066130123 0.6284\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
